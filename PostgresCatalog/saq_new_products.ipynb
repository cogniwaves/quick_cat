{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 Extract data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATADIR = \"../data/saq/products/\"\n",
    "\n",
    "def extract_saq_fields_from_record(item):\n",
    "    pdets = item.get(\"product_details\", {})\n",
    "    return {\n",
    "        \"url\": item.get(\"url\"),\n",
    "        \"product_name\": item.get(\"product_name\"),\n",
    "        \"price\": item.get(\"price\"),\n",
    "        \"breadcrumb\": item.get(\"breadcrumb\"),\n",
    "        \"product_details_pays\": pdets.get(\"Pays\"),\n",
    "        \"product_details_region\": pdets.get(\"Région\"),\n",
    "        \"product_details_appellation\": pdets.get(\"Appellation d'origine\"),\n",
    "        \"product_details_designation\": pdets.get(\"Désignation réglementée\"),\n",
    "        \"product_details_cepage\": pdets.get(\"Cépage\") or pdets.get(\"Cépages\"),\n",
    "        \"product_details_degre_alcool\": pdets.get(\"Degré d'alcool\"),\n",
    "        \"product_details_couleur\": pdets.get(\"Couleur\"),\n",
    "        \"product_details_format\": pdets.get(\"Format\"),\n",
    "        \"product_details_producteur\": pdets.get(\"Producteur\"),\n",
    "        \"product_details_agent\": pdets.get(\"Agent promotionnel\"),\n",
    "        \"product_details_code_saq\": pdets.get(\"Code SAQ\"),\n",
    "        \"product_details_code_cup\": pdets.get(\"Code CUP\"),\n",
    "        \"product_details_tasting_notes\": item.get(\"tasting_notes\"),\n",
    "        \"product_details_pairings\": item.get(\"pairings\"),\n",
    "        \"product_details\": pdets\n",
    "    }\n",
    "\n",
    "def load_data2(batch_start=1, batch_end=10):\n",
    "    data = []\n",
    "    for i in range(batch_start, batch_end):\n",
    "        file_path = os.path.join(DATADIR, f'batch_{i}.json')\n",
    "        print(f\"Loading {file_path}\")\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as f:\n",
    "                records = json.load(f)\n",
    "                cleaned = [extract_saq_fields_from_record(rec) for rec in records]\n",
    "                data.append(pd.DataFrame(cleaned))\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")\n",
    "    return pd.concat(data, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data2(batch_start = 11, batch_end=501)\n",
    "df = df[df['product_name'].notna() & (df['product_name'].str.strip() != '')]\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "DB_URL = \"postgresql://postgres.oqvdwtiwrzyjpnouwxch:f87JpR9Uvud6NR3HwbP@aws-0-ca-central-1.pooler.supabase.com:5432/postgres\"\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwines = df[df['breadcrumb'].str.startswith(\"Produits > Vin\", na=False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row in dfwines, query table subcategory2 and category to check if (dfwine['product_details_couleur'] = category.category_name_fr   \n",
    "# and dfwine['product_details_appellation'] = subcategory2.subcategory_name_fr)\n",
    "# SELECT count(1) from subcategory2, category where subcategory2.category_id = category.category_id and subcategory2.subcategory_name_fr = dfwine['product_details_appellation'] and category.category_name_fr = dfwine['product_details_couleur']\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "def update_subcategories(conn, dfwines):\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Connection opened\")\n",
    "\n",
    "    SELECT_COUNT_SQL = \"\"\"\n",
    "        SELECT count(1)\n",
    "        FROM subcategory2\n",
    "        JOIN category ON subcategory2.category_id = category.category_id\n",
    "        WHERE subcategory2.subcategory_name_fr = %s\n",
    "        AND category.category_name_fr = %s\n",
    "    \"\"\"\n",
    "    \n",
    "    SELECT_CATEGORY_SQL = \"SELECT category_id FROM category WHERE category_name_fr = %s\"\n",
    "    SELECT_MAX_CODE_SQL = \"\"\"\n",
    "        SELECT MAX(subcategory_code)\n",
    "        FROM subcategory2\n",
    "        WHERE subcategory_code > 810000000 AND subcategory_code < 820000000\n",
    "    \"\"\"\n",
    "    \n",
    "    INSERT_SUBCATEGORY_SQL = \"\"\"\n",
    "        INSERT INTO subcategory2 (subcategory_id, subcategory_code, subcategory_name_fr, subcategory_name_en, category_id)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    for _, row in dfwines.iterrows():\n",
    "        appellation = row.get('product_details_appellation') or \"None\"\n",
    "        couleur = row.get('product_details_couleur') or \"None\"\n",
    "\n",
    "        try:\n",
    "            cursor.execute(SELECT_COUNT_SQL, (appellation, couleur))\n",
    "            if cursor.fetchone()[0]:\n",
    "                #print(f\"Found: {appellation} - {couleur}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Not found: {appellation} - {couleur}\")\n",
    "            cursor.execute(SELECT_CATEGORY_SQL, (couleur,))\n",
    "            cat_result = cursor.fetchone()\n",
    "            if not cat_result:\n",
    "                print(f\"Category not found for: {couleur}\")\n",
    "                continue\n",
    "\n",
    "            category_id = cat_result[0]\n",
    "            cursor.execute(SELECT_MAX_CODE_SQL)\n",
    "            max_code = cursor.fetchone()[0] or 810000000\n",
    "            subcategory_code = max_code + 1\n",
    "\n",
    "            subcategory_id = str(uuid4())\n",
    "            cursor.execute(INSERT_SUBCATEGORY_SQL, (\n",
    "                subcategory_id, subcategory_code, appellation, appellation, category_id\n",
    "            ))\n",
    "            conn.commit()\n",
    "            #print(f\"Inserted: {appellation} with ID {subcategory_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            conn.rollback()\n",
    "    cursor.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)\n",
    "try: \n",
    "    update_subcategories(conn, dfwines)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 insert into products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "DB_URL = \"postgresql://postgres.oqvdwtiwrzyjpnouwxch:f87JpR9Uvud6NR3HwbP@aws-0-ca-central-1.pooler.supabase.com:5432/postgres\"\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from datetime import datetime, timezone\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_or_generate_upc(cursor, row, log_file):\n",
    "    product_upc = row.get('product_details_code_cup') or \"8888\"\n",
    "    product_name = row.get('product_name')\n",
    "\n",
    "    if product_upc != \"8888\" or not product_name:\n",
    "        return product_upc\n",
    "\n",
    "    cursor.execute(\"SELECT product_upc FROM product WHERE product_name_fr = %s\", (product_name,))\n",
    "    result = cursor.fetchone()\n",
    "\n",
    "    if result:\n",
    "        return result[0]\n",
    "\n",
    "    log_file.write(f\"UPC not found for {product_name}, generating new one.\\n\")\n",
    "    cursor.execute(\"SELECT nextval('octo_upc')\")\n",
    "    new_upc = str(cursor.fetchone()[0])\n",
    "    log_file.write(f\"Generated UPC: {new_upc} for {product_name}\\n\")\n",
    "    return new_upc\n",
    "\n",
    "def get_subcategory_id(cursor, row):\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT s.subcategory_id\n",
    "        FROM subcategory2 s\n",
    "        JOIN category c ON s.category_id = c.category_id\n",
    "        JOIN family f ON f.family_id = c.family_id\n",
    "        WHERE f.family_name_fr = 'Vin'\n",
    "          AND c.category_name_fr = %s\n",
    "          AND s.subcategory_name_fr = %s\n",
    "    \"\"\", (\n",
    "        row.get('product_details_couleur') or \"None\",\n",
    "        row.get('product_details_appellation') or \"None\"\n",
    "    ))\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else None\n",
    "\n",
    "def upsert_wines(df, conn):\n",
    "    df['product_id'] = None\n",
    "    df['product_upc'] = None\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    os.makedirs(\"../logs\", exist_ok=True)\n",
    "    log_file = open(\"../logs/insert_reject.log\", \"a\")\n",
    "\n",
    "    wines = df[df['breadcrumb'].str.startswith(\"Produits > Vin\", na=False)].copy()\n",
    "    wines['product_details_couleur'] = wines['product_details_couleur'].str.strip()\n",
    "\n",
    "    for idx in tqdm(wines.index, total=len(wines), desc=\"Upserting wines\"):\n",
    "        row = df.loc[idx]\n",
    "        product_name = row.get('product_name')\n",
    "        if not product_name:\n",
    "            log_file.write(f\"Product name is empty for index {idx}\\n\")\n",
    "            continue\n",
    "        product_id = None\n",
    "        product_upc = None\n",
    "        subcategory_id = None\n",
    "        details_json = None\n",
    "\n",
    "        try:\n",
    "            df.at[idx, 'product_details_appellation'] = row.get('product_details_appellation') or \"None\"\n",
    "            df.at[idx, 'product_details_couleur'] = row.get('product_details_couleur') or \"None\"\n",
    "\n",
    "            product_upc = get_or_generate_upc(cursor, row, log_file)\n",
    "            df.at[idx, 'product_upc'] = product_upc\n",
    "\n",
    "            cursor.execute(\"SELECT 1 FROM product WHERE product_upc = %s\", (product_upc,))\n",
    "            if cursor.fetchone():\n",
    "                continue\n",
    "\n",
    "            subcategory_id = get_subcategory_id(cursor, row)\n",
    "            if not subcategory_id:\n",
    "                log_file.write(f\"Subcategory not found for {row['product_details_couleur']} - {row['product_details_appellation']}\\n\")\n",
    "                continue\n",
    "\n",
    "            product_id = str(uuid4())\n",
    "            df.at[idx, 'product_id'] = product_id\n",
    "\n",
    "            details_json = json.dumps(row['product_details'], default=str)\n",
    "            now = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO product (\n",
    "                    product_id, product_name_fr, product_name_en, product_name_es,\n",
    "                    product_upc, producer_code, subcategory_id, details,\n",
    "                    unit_equivalence_qty, product_code, refresh_date\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\", (\n",
    "                product_id, product_name, product_name, product_name,\n",
    "                product_upc, row.get('product_details_code_saq'),\n",
    "                subcategory_id, details_json, 1, row.get('product_details_code_saq'),\n",
    "                now\n",
    "            ))\n",
    "            conn.commit()\n",
    "\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            log_file.write(f\"{datetime.now()} Error inserting {product_name}: {e}\\n\")\n",
    "            log_file.write(f\"1: {product_id}, 5: {product_upc}, 7: {subcategory_id}, 8: {details_json}\\n\")\n",
    "\n",
    "    log_file.close()\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_URL)\n",
    "try: \n",
    "    upsert_wines(dfwines, conn)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 update Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "DB_URL = \"postgresql://postgres.oqvdwtiwrzyjpnouwxch:f87JpR9Uvud6NR3HwbP@aws-0-ca-central-1.pooler.supabase.com:5432/postgres\"\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def update_product_volumes(df, conn):\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     # Clean and filter rows with valid formats\n",
    "#     df = df[df['product_details_format'].notnull()].copy()\n",
    "\n",
    "#     for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Updating volume & unit info\"):\n",
    "#         fmt = row['product_details_format'].replace(',', '.').strip()\n",
    "\n",
    "#         # Match format like \"750 ml\", \"1 L\", \"1.5 L\", etc.\n",
    "#         match = re.match(r'([\\d\\.]+)\\s*([a-zA-Z]+)', fmt)\n",
    "#         if not match:\n",
    "#             print(f\"Could not parse format: {fmt}\")\n",
    "#             continue\n",
    "\n",
    "#         try:\n",
    "#             volume_qty = float(match.group(1))\n",
    "#             print(f\"Parsed volume quantity: {volume_qty}\")\n",
    "#         except ValueError:\n",
    "#             print(f\"Invalid volume quantity: {match.group(1)}\")\n",
    "#             continue\n",
    "#         unit = match.group(2).lower()\n",
    "\n",
    "#         # Get lookup_id from measure_lkp\n",
    "#         try:\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 SELECT lookup_id\n",
    "#                 FROM measure_lkp\n",
    "#                 WHERE lower(lookup_abbreviation_fr) = %s\n",
    "#             \"\"\", (unit,))\n",
    "#             result = cursor.fetchone()\n",
    "#             if not result:\n",
    "#                 print(f\"No lookup_id found for unit: {unit}\")\n",
    "#                 continue\n",
    "\n",
    "#             volume_equivalence_id = result[0]\n",
    "#             fixed_unit_id = 'a9e5e8dd-098c-4f76-86f8-08f36620ac0c'  # fixed UUID\n",
    "\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 UPDATE product\n",
    "#                 SET volume_equivalence_qty = %s,\n",
    "#                     unit_equivalence_id = %s,\n",
    "#                     volume_equivalence_id = %s\n",
    "#                 WHERE product_upc = %s\n",
    "#             \"\"\", (\n",
    "#                 volume_qty,\n",
    "#                 fixed_unit_id,\n",
    "#                 volume_equivalence_id,\n",
    "#                 row.get('product_details_code_cup')\n",
    "#             ))\n",
    "#             conn.commit()\n",
    "#         except Exception as e:\n",
    "#             conn.rollback()\n",
    "#             print(f\"Error updating {row.get('product_name', '')}: {e}\")\n",
    "\n",
    "#     cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# configure logging once at top-level of your module\n",
    "logging.basicConfig(\n",
    "    filename=\"../logs/volume_updates.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    ")\n",
    "\n",
    "FORMAT_REGEX = re.compile(r\"^\\s*([\\d.]+)\\s*([A-Za-z]+)\\s*$\")\n",
    "SELECT_LKP_SQL = \"\"\"\n",
    "    SELECT lookup_id\n",
    "      FROM measure_lkp\n",
    "     WHERE lower(lookup_abbreviation_fr) = %s\n",
    "\"\"\"\n",
    "UPDATE_PROD_SQL = \"\"\"\n",
    "    UPDATE product\n",
    "       SET volume_equivalence_qty = %s,\n",
    "           unit_equivalence_id     = %s,\n",
    "           volume_equivalence_id   = %s\n",
    "     WHERE product_upc = %s\n",
    "\"\"\"\n",
    "\n",
    "FIXED_UNIT_ID = \"a9e5e8dd-098c-4f76-86f8-08f36620ac0c\"\n",
    "\n",
    "def update_product_volumes(df, conn):\n",
    "    df = df[df[\"product_details_format\"].notna()].copy()\n",
    "    with conn.cursor() as cur:\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Updating volumes\"):\n",
    "            fmt = row[\"product_details_format\"].replace(\",\", \".\")\n",
    "            m = FORMAT_REGEX.match(fmt)\n",
    "            if not m:\n",
    "                logging.warning(\"Could not parse format: %r\", fmt)\n",
    "                continue\n",
    "\n",
    "            qty_str, unit = m.groups()\n",
    "            try:\n",
    "                qty = float(qty_str)\n",
    "            except ValueError:\n",
    "                logging.warning(\"Invalid quantity %r in %r\", qty_str, fmt)\n",
    "                continue\n",
    "\n",
    "            unit = unit.lower()\n",
    "            cur.execute(SELECT_LKP_SQL, (unit,))\n",
    "            lkp = cur.fetchone()\n",
    "            if not lkp:\n",
    "                logging.warning(\"No lookup_id for unit %r\", unit)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                cur.execute(\n",
    "                    UPDATE_PROD_SQL,\n",
    "                    (qty, FIXED_UNIT_ID, lkp[0], row.get(\"product_details_code_cup\")),\n",
    "                )\n",
    "                conn.commit()\n",
    "            except Exception as e:\n",
    "                conn.rollback()\n",
    "                logging.error(\"Error updating %r: %s\", row.get(\"product_name\"), e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)\n",
    "try: \n",
    "    update_product_volumes(dfwines, conn)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --Step 4 insert product_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "DB_URL = \"postgresql://postgres.oqvdwtiwrzyjpnouwxch:f87JpR9Uvud6NR3HwbP@aws-0-ca-central-1.pooler.supabase.com:5432/postgres\"\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from uuid import uuid4\n",
    "\n",
    "# def populate_product_sizes(df, conn):\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Populating product_size\"):\n",
    "#         upc = row.get(\"product_details_code_cup\")\n",
    "\n",
    "#         if not upc:\n",
    "#             continue\n",
    "\n",
    "#         try:\n",
    "#             # Retrieve product info\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 SELECT product_id, product_upc,\n",
    "#                     unit_equivalence_qty, unit_equivalence_id,   \n",
    "#                     volume_equivalence_qty, volume_equivalence_id                           \n",
    "#                 FROM product\n",
    "#                 WHERE product_upc = %s\n",
    "#             \"\"\", (upc,))\n",
    "#             product = cursor.fetchone()\n",
    "\n",
    "#             if not product:\n",
    "#                 continue  # Product not found\n",
    "\n",
    "#             product_id, db_upc, unit_qty, unit_id,  vol_qty, vol_eq_id = product\n",
    "\n",
    "#             # Check if already exists for UPC\n",
    "#             cursor.execute(\"SELECT 1 FROM product_sizes WHERE upc = %s\", (upc,))\n",
    "#             if cursor.fetchone():\n",
    "#                 continue  # Already exists for this UPC\n",
    "\n",
    "            \n",
    "#             # Insert new entry\n",
    "#             size_id = str(uuid4())\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 INSERT INTO product_sizes (\n",
    "#                     product_size_id, product_id,\n",
    "#                     upc,\n",
    "#                     unit_equivalence_qty, unit_equivalence_id,\n",
    "#                     volume_equivalence_measure_id, volume_equivalence_qty\n",
    "#                 )\n",
    "#                 VALUES (%s, %s, %s, %s, %s,%s, %s)\n",
    "#             \"\"\", (\n",
    "#                 size_id, product_id,\n",
    "#                 upc,\n",
    "#                 unit_qty, unit_id,\n",
    "#                 vol_eq_id, vol_qty\n",
    "#             ))\n",
    "#             conn.commit()\n",
    "\n",
    "#         except Exception as e:\n",
    "#             conn.rollback()\n",
    "#             print(f\"Error inserting product_size for {row.get('product_name')}: {e}\")\n",
    "\n",
    "#     cursor.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate_product_sizes(df, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "DB_URL = \"postgresql://postgres.oqvdwtiwrzyjpnouwxch:f87JpR9Uvud6NR3HwbP@aws-0-ca-central-1.pooler.supabase.com:5432/postgres\"\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_distributor_id(conn, distributor_name):\n",
    "    cursor = conn.cursor()\n",
    "    try: \n",
    "        result = cursor.execute(f\"SELECT distributor_id FROM distributor WHERE distributor_name_fr = '{distributor_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching distributor ID: {e}\")\n",
    "        distributor_id = None\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        distributor_id = result[0]\n",
    "    else:\n",
    "        print(\"Distributor not found\")\n",
    "        distributor_id = None\n",
    "    cursor.close()\n",
    "    return distributor_id\n",
    "\n",
    "def not_exist_in_package(conn, product_id,  distributor_id):\n",
    "    #print(f\"Checking if product {product_id} exists in package for distributor {distributor_id}\")\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"SELECT 1 FROM package WHERE product_id = %s AND distributor_id = %s\", (product_id, distributor_id))\n",
    "        result = cursor.fetchone()\n",
    "        return not result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking package existence: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "def insert_package(conn, df, distibutor_name):\n",
    "\n",
    "    SQL_CHECK_DIST_CODE = \"\"\"\n",
    "        SELECT distributor_code from package where distributor_code = %s\n",
    "    \"\"\"\n",
    "\n",
    "    distributor_id = get_distributor_id(conn, distibutor_name)\n",
    "    if not distributor_id:\n",
    "        print(\"Distributor ID is None, skipping package insertion.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Inserting packages\"):\n",
    "        if not_exist_in_package(conn, row['product_id'], distributor_id):\n",
    "            \n",
    "            distributor_code = row.get(\"product_details_code_saq\")\n",
    "            #print(f\"Distributor code: {distributor_code}\")\n",
    "            pformat='BT'\n",
    "            package_id = str(uuid4())\n",
    "            packaging = row.get(\"product_details_format\")\n",
    "            product_id = row[\"product_id\"]\n",
    "            if product_id is None:\n",
    "                print(f\"Product ID is None for {row.get('product_name')}, skipping.\")\n",
    "                continue\n",
    "            # print(f\"Product ID: {product_id}\")\n",
    "\n",
    "            SQL = \"\"\"\n",
    "                INSERT INTO package (package_id, distributor_id, packaging, distributor_code, format, product_id)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (package_id) DO NOTHING\n",
    "            \"\"\"\n",
    "            try:\n",
    "                cursor.execute(SQL, (package_id, distributor_id, packaging, distributor_code, pformat, product_id))\n",
    "                conn.commit()\n",
    "            except Exception as e:\n",
    "                conn.rollback()\n",
    "                print(f\"Error inserting package for {row.get('product_name')}: {e}\")\n",
    "\n",
    "\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfwines[dfwines['product_id']== None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_URL)\n",
    "try: \n",
    "    insert_package(conn, dfwines, \"SAQ\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting package: {e}\")\n",
    "    conn.close()\n",
    "finally:\n",
    "    conn.close()\n",
    "    print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(DB_URL)\n",
    "insert_package(conn, dfwines, 'SAQ')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwines[dfwines['product_name']=='Domaine Porto Carras Malagouzia 2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data2(batch_start = 1501, batch_end=1908)\n",
    "df = df[df['product_name'].notna() & (df['product_name'].str.strip() != '')]\n",
    "\n",
    "dfwines = df[df['breadcrumb'].str.startswith(\"Produits > Vin\", na=False)].copy()\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)\n",
    "\n",
    "try: \n",
    "    update_subcategories(conn, dfwines)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)\n",
    "try: \n",
    "    upsert_wines(dfwines, conn)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)\n",
    "try: \n",
    "    update_product_volumes(dfwines, conn)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    conn.close()\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)\n",
    "try: \n",
    "    insert_package(conn, dfwines, \"SAQ\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting package: {e}\")\n",
    "    conn.close()\n",
    "finally:\n",
    "    conn.close()\n",
    "    print(\"Connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
